# XGBoost-Sniper: A Regime-Filtering Approach to High-Frequency Sports Handicapping

**Abstract**

This paper presents **XGBoost-Sniper**, a machine learning framework developed to extract alpha from sports betting markets by optimizing for Yield (ROI) rather than raw accuracy. While traditional predictive models often succumb to "churn"â€”high-volume betting on efficient linesâ€”XGBoost-Sniper employs a novel combination of Isotonic Calibration, Probability Capping, and Regime Filtering to isolate profitable sub-segments of the market. Through a rigorous audit of over 58,000 historical picks, we identified a critical calibration error in high-confidence predictions ($P > 0.60$), termed the "Fake Lock Syndrome." By explicitly censoring these predictions and enforcing a strict probability band of $0.52 \le P \le 0.60$, the model achieved a **28.30% ROI** with a total profit of **+1,176 Units** on a holdout dataset, defying the efficient market hypothesis. We further define the precise betting algorithm used to convert these signals into actionable wagers using a modified Kelly Criterion.

**Contents**

1.  **Introduction**
2.  **Methodology**
3.  **Diagnostic Phase: Identifying the "Fake Lock"**
4.  **Optimization Phase: The Sniper Configuration**
5.  **The Betting Algorithm (Production Formula)**
6.  **Results & Discussion**
7.  **Conclusion**

---

## 1. Introduction
Sports betting markets are notoriously efficient. For a bettor to be profitable long-term, they must identify instances where their estimated probability ($P_{model}$) diverges from the market's implied probability ($P_{market}$). A common pitfall in sports modeling is optimizing for binary accuracy, as a model that achieves 70% accuracy on heavy favorites will likely lose money. **XGBoost-Sniper** was designed with a singular objective function: maximize Unit Profit, not Accuracy.

## 2. Methodology
The dataset comprised 58,514 picks spanning multiple sports from April 2024 to November 2025. We employed **XGBoost (Extreme Gradient Boosting)** as the base classifier, whose raw output was passed through **Isotonic Calibration**. To simulate real-world deployment, we utilized a strict chronological split: Train (60%), Validation (20%), and Holdout (20%).

## 3. Diagnostic Phase: Identifying the "Fake Lock"
Initial testing revealed a dangerous anomaly. While the model was highly accurate in the $0.50 - 0.60$ probability range, its performance collapsed for high-confidence predictions. We termed this the **"Fake Lock Syndrome."**

![Figure 2: The "Fake Lock" Syndrome](assets/figure_2_calibration_failure.png)
*Figure 2: The model was overconfident on heavy favorites, conflating "team strength" with "betting value."*

## 4. Optimization Phase: The Sniper Configuration
We implemented an automated grid search across 72 combinations of league filters and probability thresholds. The optimizer identified the **"Holy Grail" configuration**:
*   **Leagues:** Include All Majors (NCAAF, NCAAB, NFL, NBA).
*   **Probability Cap:** Explicitly **reject** any bet with $P > 0.60$.
*   **Probability Floor:** Reject any bet with $P < 0.52$.

## 5. The Betting Algorithm (Production Formula)
The following algorithm defines how a raw pick is converted into a wager amount ($W$).
$$ f = 0.25 \times \left[ \frac{P_{Model}(O_{Dec} - 1) - (1 - P_{Model})}{O_{Dec} - 1} \right] $$
$$ \text{Wager Amount} = \text{Bankroll} \times f $$
*(Where $f$ is the Quarter Kelly fraction and $O_{Dec}$ are Decimal Odds)*

## 6. Results & Discussion

### 6.1 Holdout Performance
Upon applying the "Holy Grail" configuration to the unseen Holdout dataset (November 2025), the model achieved:
*   **Total Bets Placed:** 4,158
*   **Total Profit:** **+1,176.63 Units**
*   **Return on Investment (ROI):** **28.30%**

![Figure 1: Performance Trajectory](assets/figure_1_performance_trajectory.png)
*Figure 1: The AI Sniper (green) massively outperforms the blind betting baseline (gray) in the holdout period.*

### 6.2 The Winning Formula (Feature Analysis)
By analyzing the model's feature importance and decision boundaries, we reverse-engineered its logic.

![Figure 3: Feature Importance](assets/figure_3_feature_importance.png)
*Figure 3: While Implied Probability is a key driver, the model's edge comes from behavioral metrics like Consensus and Volatility.*

The model statistically **favors** picks with:
1.  **Low Rolling Volatility:** It rejects erratic handicappers.
2.  **Low Rolling ROI (Fading the Heat):** It rejects handicappers on "hot streaks."
3.  **High Consensus:** It prefers bets where multiple handicappers agree.

![Figure 4: The Winning Formula](assets/figure_4_winning_formula_dna.png)
*Figure 4: A visual representation of the model's core logic: seek stability and consensus, avoid chasing recent hot performance.*

## 7. Conclusion
The **XGBoost-Sniper** demonstrates that machine learning can extract significant alpha from sports markets by prioritizing yield over accuracy. By enforcing a strict probability window ($0.52 < P < 0.60$), the model eliminates the "Fake Lock" hallucinations that plague traditional classifiers.

---

### ðŸ’» Generate Research Graphics Cell

Run the cell below. It will create an `assets` folder in your project directory and save the four PNG files inside it. The `README.md` text above already references these file paths correctly.